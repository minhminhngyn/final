import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
import streamlit as st
from sklearn.neighbors import NearestNeighbors
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv, GATConv
import scipy.io
import os

# ======================== MODEL ========================
class HybridGATGCN(torch.nn.Module):
    def __init__(self, in_dim, hidden_dim, out_dim, heads=8, dropout=0.27):
        super(HybridGATGCN, self).__init__()
        self.dropout = dropout

        # Layer 1
        self.gcn1 = GCNConv(in_dim, hidden_dim)
        self.bn1 = torch.nn.BatchNorm1d(hidden_dim)
        self.gat1 = GATConv(hidden_dim, hidden_dim, heads=heads, concat=False, dropout=dropout)

        # Layer 2
        self.gcn2 = GCNConv(hidden_dim, hidden_dim)
        self.bn2 = torch.nn.BatchNorm1d(hidden_dim)
        self.gat2 = GATConv(hidden_dim, out_dim, heads=heads, concat=False, dropout=dropout)

    def forward(self, x, edge_index):
        # Layer 1
        x = self.gcn1(x, edge_index)
        x = self.bn1(x)
        x = torch.nn.functional.relu(x)
        x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)
        x = self.gat1(x, edge_index)

        # Layer 2
        x = torch.nn.functional.relu(x)
        x = self.gcn2(x, edge_index)
        x = self.bn2(x)
        x = torch.nn.functional.relu(x)
        x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)
        x = self.gat2(x, edge_index)

        return torch.nn.functional.log_softmax(x, dim=1)
# ======================== STREAMLIT UI ========================
st.set_page_config(page_title="Batch Transaction Detection with GAT-GCN", layout="wide")
st.title("üìä Batch Transaction Anomaly Detection")

uploaded_mat = st.file_uploader("Upload your .mat file (containing 'features' and 'label')", type=["mat"])

if uploaded_mat is not None:
    st.success("üìÅ File uploaded successfully.")

    # N√∫t ch·ªâ hi·ªán khi c√≥ file
    if st.button("üîç Analyze"):
        with open("temp_data.mat", "wb") as f:
            f.write(uploaded_mat.read())
def load_test_data(file_path):
    """
    T·∫£i d·ªØ li·ªáu ki·ªÉm th·ª≠ t·ª´ file CSV
    """
    try:
        df = pd.read_csv(file_path)
        if 'label' not in df.columns:
            raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt 'label'")
        labels = df.pop('label').values
        features = df.values
        return features, labels
    except Exception as e:
        st.error(f"L·ªói: {e}")
        raise
def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    test_file_path = "preprocessed_data.csv"
    try:
        features, labels = load_test_data(test_file_path)
        print(f"Loaded test data: {features.shape[0]} samples, {features.shape[1]} features")
    except FileNotFoundError:
        print("Preprocessed data file not found. Please run the preprocessing step first.")
        return

    data = create_test_graph(features, labels)
    data = data.to(device)
    print(f"Created test graph with {data.x.shape[0]} nodes and {data.edge_index.shape[1]} edges")

    model_path = "trained_model.pt"
    try:
        num_classes = 2 # Assuming binary classification
        model = HybridGATGCN(
            in_dim=features.shape[1],  # Update in_dim to features.shape[1]
            hidden_dim=256,  # Correct hidden dimension
            out_dim=num_classes,
            heads=8,  # Correct heads
            dropout=0.27  # Correct dropout
        ).to(device)

        model.load_state_dict(torch.load(model_path, map_location=device))
        print(f"Loaded model from {model_path}")
    except FileNotFoundError:
        print(f"Kh√¥ng t√¨m th·∫•y t·ªáp m√¥ h√¨nh {model_path}. S·ª≠ d·ª•ng m√¥ h√¨nh ch∆∞a hu·∫•n luy·ªán.")
        num_classes = len(np.unique(labels))
        model = HybridGATGCN(
            in_dim=features.shape[1],
            hidden_dim=128,
            out_dim=num_classes,
            heads=8,
            dropout=0.27
        ).to(device)

    results = evaluate_model(model, data)
    class_names = [f'Class {i}' for i in range(results['confusion_matrix'].shape[0])]
    visualize_results(results, class_names)

    results_df = pd.DataFrame({
        'true_label': results['true_labels'],
        'predicted_label': results['predictions']
    })


    for i in range(results['probabilities'].shape[1]):
        results_df[f'prob_class_{i}'] = results['probabilities'][:, i]

    results_df.to_csv('test_predictions.csv', index=False)
    st.success("‚úÖ Prediction Completed")
    st.dataframe(df_result.head(20))

    csv = df_result.to_csv(index=False).encode('utf-8')
    st.download_button("üì• Download Prediction Results", data=csv, file_name="prediction_results.csv", mime='text/csv')
